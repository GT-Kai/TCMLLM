{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9befb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading config...\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      ">>> Loading tokenizer...\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      ">>> Loading base model...\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/accelerate/utils/torch_xla.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at ./chatglm-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      ">>> Loading prefix tuning checkpoint...\n",
      ">>> Prefix encoder loaded.\n",
      ">>> Model loaded on cuda:1.\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m1675273\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m1675273\u001b[0m]\n",
      "\u001b[31mERROR\u001b[0m:    Traceback (most recent call last):\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/uvicorn/_compat.py\", line 60, in asyncio_run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/asyncio/base_events.py\", line 636, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/uvicorn/server.py\", line 70, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/uvicorn/server.py\", line 331, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/starlette/routing.py\", line 701, in lifespan\n",
      "    await receive()\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/site-packages/uvicorn/lifespan/on.py\", line 137, in receive\n",
      "    return await self.receive_queue.get()\n",
      "  File \"/home/lick/tools/anaconda3/envs/TCMLLM/lib/python3.10/asyncio/queues.py\", line 159, in get\n",
      "    await getter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! uvicorn server:app --host 0.0.0.0 --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e620b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620181f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1613d291",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCMLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
